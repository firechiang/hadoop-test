### HDFS基础理论
##### 存储模型
```bash
1. 文件线性切割成块（Block=128M），每个块有偏移量（Offset：块的起始位置在整个文件所在的位置），整个文件就是一个Byte数组
2. Block分散存储在集群节点当中
3. 单一文件Block大小一致（不包括最后一个块），文件与文件可以不一致
4. Block可以设置副本数，副本无序分散在不同节点之中 （副本数不要超过节点数）
5. 文件上传可以设置Block大小（最小1M，最大和默认都是128M）和副本数（如果计算程序较多，可以考虑增加副本数，以减少单机的资源占用。因为计算程序会在副本所在的机器上开盘计算进程）
6. 已上传的文件Block副本数可以调整，大小不变
7. 只支持一次写入多次读取（就是不可以修改），同一时刻只有一个写入者
8. 可以append追加数据
```

##### 副本放置策略
```bash
第一个副本：如果在集群之内（就是当前客户端上也有DataNode）就放置在当前的DataNode之上，如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点
第二个副本：放置在于第一个副本不同的机架的节点上
第三个副本：与第二个副本相同机架但不同的节点
更多副本：随机节点
```

##### 架构模型（主从模型）
```bash
1. 文件元数据MetaData（主：NameNode节点保存文件元数据），文件数据（从：DataNode节点保存文件Block数据）
       1.1 （主）元数据（数据大小，创建时间，所在位置等等信息）
       1.2 （从）数据本身
2. DataNode与NameNode保持心跳，向NameNode提交Block列表信息（当前有几个DataNode可用）  
3. HdfsClient与NameNode交换元数据信息
4. HdfsClient与DataNode交换文件Block数据
5. DataNode利用服务器本地文件系统存储数据块
```
##### [一、单节点搭建][1]

[1]: https://github.com/firechiang/hadoop-test/tree/master/hdfs/docs/1-setup-single-node.md


















